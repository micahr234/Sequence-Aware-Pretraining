# Default configuration for Sequence-Aware Pretraining

# Model Configuration
model:
  base_name: "Qwen/Qwen3-4B-Base"
  # Base model to be trained using Discounted Log-Suffix SFT.
  # Effect: The foundation model that will be fine-tuned. Should be a causal language model
  # compatible with the task. GPT-2 provides a good balance of performance and efficiency.
  
  output_name: "sequence-aware-default"
  # Name for the fine-tuned model when pushing to Hugging Face Hub.
  # Effect: This exact name will be used for the hub repository.
  # Should be unique to avoid conflicts with existing models.
  
  device: "auto"
  # Device to run training on.
  # Proposed by: PyTorch framework for device management.
  # Effect: "auto" automatically selects CUDA if available, otherwise CPU. Can be explicitly
  # set to "cuda", "cpu", or specific device IDs like "cuda:0".
  # Reference: https://pytorch.org/docs/stable/tensor_attributes.html#torch.device

# Dataset Configuration
dataset:
  name: "c4"
  # Dataset to use for training.
  # Effect: C4 (Clean Common Crawl) is excellent for broad pretraining with diverse web text.
  # Provides high-quality, diverse text for general language understanding.
  
  max_examples: null
  # Maximum number of examples to use from the dataset.
  # Effect: Limits the dataset size for faster experimentation. Set to null to use all examples.
  # Useful for debugging and quick experiments with smaller subsets.
  
  question_reasoning_join_string: "\n\n"
  # Join string between question and reasoning.
  # Effect: Used when constructing prompts with question and reasoning components.
  # Example: question + question_reasoning_join_string + reasoning
  # For GSM8K, this is typically "\n\n" to separate question from reasoning.
  
  reasoning_answer_join_string: "\n\nThe answer is: "
  # Join string between reasoning and answer.
  # Effect: Used to combine reasoning with final answer during training.
  # Format: text (question + reasoning) + reasoning_answer_join_string + answer.
  # This is the pattern the model learns for generating answers after reasoning.

# Training Configuration
training:
  # Training Parameters
  parameters:
    max_seq_length: 1024
    # Maximum length of input sequences.
    # Effect: Standard length for pretraining. Longer sequences for better context.
    # Typical range for pretraining: 512-2048.
    
    train_on_answers_only: false
    # Whether to only train on answer portions, zeroing out loss for text portions.
    # Effect: When true, loss is only computed on answer tokens (text portion is masked).
    # When false (default), trains on full text when no answer exists, or only on answer when answer exists.
    # Use true for fine-tuning scenarios where you only want to learn from answers.
    # Use false for pretraining where you want to learn from all text.

  # Optimizer Settings
  optimizer:
    type: null
    # Optimizer type to use. Options: "adamw_torch", "adamw_hf", "adamw_torch_fused", 
    # "sgd", "adagrad", "adamw_8bit", "adamw_bnb_8bit", "lion", "lion_8bit", 
    # "paged_adamw_8bit", "paged_lion_8bit", "rmsprop", etc.
    # Effect: Selects the optimizer implementation. Default (null) uses "adamw_torch".
    # "adamw_torch_fused" can be faster on modern GPUs. "adamw_8bit" reduces memory usage.
    # Reference: https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.TrainingArguments.optim
    
    lr: 1e-4
    # Learning rate for the optimizer.
    # Effect: Standard learning rate for pretraining. Higher than fine-tuning rates.
    # Typical range for pretraining: 1e-4 to 5e-4.
    
    weight_decay: 0.0
    # L2 regularization coefficient for the optimizer.
    # Effect: Standard weight decay for pretraining. Higher than fine-tuning values.
    # Typical range for pretraining: 0.1 to 0.2.
    
    gamma: 0.99
    # Discount factor for position-based weighting in discounted log-suffix training.
    # Effect: Higher gamma for pretraining to emphasize later tokens more strongly.
    # Typical range for pretraining: 0.95 to 0.99.
    
    num_epochs: 1
    # Number of complete passes through the training dataset.
    # Effect: Standard for pretraining. More epochs than fine-tuning.
    # Typical range for pretraining: 1-5 epochs.
    
    batch_size: 16
    # Number of examples processed in each training step.
    # Effect: Larger batch size for pretraining. More stable gradients.
    # Typical range for pretraining: 4-16.
    
    grad_accumulation_steps: 4
    # Number of gradient accumulation steps before updating parameters.
    # Effect: Simulates larger batch sizes. Effective batch size = batch_size Ã— grad_accumulation_steps.
    # Typical range for pretraining: 2-8.
    
    dropout: 0.0
    # Dropout rate for regularization during training.
    # Effect: Standard dropout rate for pretraining. Prevents overfitting.
    # Typical range for pretraining: 0.1 to 0.2.

  # Training Schedule
  schedule:
    warmup_steps: 0
    # Number of warmup steps for learning rate scheduling.
    # Effect: Standard for pretraining. Gradual learning rate increase.
    # Typical range for pretraining: 0-1000 steps.
    
    warmup_ratio: 0.1
    # Warmup ratio as a fraction of total training steps.
    # Effect: Standard warmup ratio for pretraining. 3% of total steps.
    # Typical range for pretraining: 0.01 to 0.05.
    
    scheduler_type: "cosine"  # Options: "linear", "cosine", "constant", "polynomial"
    # Type of learning rate scheduler to use.
    # Effect: Cosine annealing is standard for pretraining. Smooth decay.
    # Typical for pretraining: "cosine" or "linear".

  # Training Control
  control:
    seed: 42
    # Random seed for reproducibility.
    # Proposed by: Standard practice in scientific computing for reproducibility.
    # Effect: Ensures reproducible results by fixing random number generation.
    # Critical for scientific experiments and debugging.
    # Reference: https://en.wikipedia.org/wiki/Random_seed
    
    log_every: 10
    # Frequency of logging training metrics.
    # Proposed by: Standard practice in ML training monitoring.
    # Effect: Controls how often training progress is logged. More frequent logging
    # provides better monitoring but increases I/O overhead.
    # Reference: Standard ML training practice

# Output Configuration
output:
  dir: "runs/default"
  # Directory to save model checkpoints and outputs.
  # Proposed by: Standard practice in ML training for output management.
  # Effect: All training outputs (checkpoints, logs, etc.) will be saved to this directory.
  # Should be unique for each experiment to avoid conflicts.
  # Reference: Standard ML training practice
  
  save_every: 1000
  # Frequency of model checkpoint saving.
  # Proposed by: Standard practice in ML training for checkpoint management.
  # Effect: Saves model checkpoints every N steps. More frequent saving provides
  # better recovery options but increases I/O overhead and disk usage.
  # Reference: Standard ML training practice

# Evaluation Configuration (optional)
evaluation:
  dataset: null
  # Dataset name to evaluate on during training (e.g., "gsm8k").
  # Effect: Model will be evaluated on this dataset at specified intervals.
  # Set to null to disable evaluation.
  
  split: "test"
  # Dataset split to use for evaluation.
  # Effect: Determines which split of the dataset to evaluate on.
  
  max_examples: null
  # Maximum number of examples to evaluate (null for all).
  # Effect: Limits evaluation size for faster training. Useful for quick checks.
  
  interval_steps: null
  # Evaluate every N training steps (null to disable).
  # Effect: Accuracy will be logged to wandb at these intervals.
  # Example: 500 means evaluate every 500 steps.
  
  answer_regex: null
  # Regex pattern to extract answer from model output (null to construct from reasoning_answer_join_string).
  # Effect: Allows using a custom regex pattern to extract answers during evaluation.
  # Example: "The answer is:\\s*(.+?)(?:\\n|$)" to match "The answer is: 42"
  # Default: If null, constructs regex from reasoning_answer_join_string by escaping it and adding capture group.

# Logging Configuration
logging:
  wandb:
    project: "sequence-aware-pretraining"
    # Weights & Biases project name for experiment tracking.
    # Proposed by: Weights & Biases for ML experiment management.
    # Effect: Groups related experiments together in the W&B dashboard.
    # Should be consistent across related experiments.
    # Reference: https://docs.wandb.ai/
    
    name: "default"
    # Weights & Biases run name for this specific experiment.
    # Proposed by: Weights & Biases for ML experiment management.
    # Effect: Identifies this specific run in the W&B dashboard. Should be unique
    # for each experiment to avoid confusion.
    # Reference: https://docs.wandb.ai/

# Authentication Configuration
auth:
  env_vars:
    hf_token: "RUNPOD_HF_TOKEN"
    # Environment variable name containing the Hugging Face authentication token.
    
    wandb_token: "RUNPOD_WANDB_TOKEN"
    # Environment variable name containing the Weights & Biases API key.
